{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70de0eb-dcbd-4f31-b5fd-22ce7f8a0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eec493-24dc-4bda-a400-a90e05fb1def",
   "metadata": {},
   "source": [
    "# I. Password Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a322c-b3b8-4d42-94e8-fe52384e7fac",
   "metadata": {},
   "source": [
    "# Step 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b8c0b-832f-4379-9b75-d507d3dff5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rockyou_path = \"rockyou.txt\"  # Update this if your dataset is in a different location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d9ccd7-17e0-4498-91ae-7c2c4adfc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "with open(rockyou_path, encoding=\"latin-1\") as f:\n",
    "    passwords = f.read().splitlines()\n",
    "\n",
    "print(f\"Total passwords loaded: {len(passwords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73085679-b23f-4641-ba4d-bd7ea3c4d0e7",
   "metadata": {},
   "source": [
    "# Step 2: Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d953f8d5-319c-4356-98ea-66ae74a7189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "passwords = list(set(passwords))\n",
    "print(f\"Total passwords after removing duplicates: {len(passwords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ddeab1-88ed-4430-b01a-907b0a40df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove passwords shorter than 4 characters\n",
    "passwords = [pwd for pwd in passwords if len(pwd) >= 4]\n",
    "print(f\"Total passwords after removing short ones: {len(passwords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e496ca-6305-4cda-b207-2780bf8a5975",
   "metadata": {},
   "source": [
    "# Step 3: Label passwords based on frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2799ee34-b3a0-49fb-b456-af6d178b607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count password occurrences\n",
    "password_counts = Counter(passwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc60fd-cf76-4606-8f7d-f7f2af60e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort passwords by frequency\n",
    "sorted_passwords = sorted(password_counts.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d2928-6aec-4cd9-8518-2b9ab30eba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds for Weak, Moderate, and Strong\n",
    "weak_threshold = 100000  # Top 100K most common passwords\n",
    "moderate_threshold = 1000000  # Next 900K passwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace56833-6a28-4418-ad9b-c95694ed9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels\n",
    "labeled_passwords = []\n",
    "for i, (password, count) in enumerate(sorted_passwords):\n",
    "    if i < weak_threshold:\n",
    "        label = \"Weak\"\n",
    "    elif i < moderate_threshold:\n",
    "        label = \"Moderate\"\n",
    "    else:\n",
    "        label = \"Strong\"\n",
    "    labeled_passwords.append((password, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6c4fa-26bb-4cf9-bbf0-801e0e92b8d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(labeled_passwords, columns=[\"Password\", \"Strength\"])\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19786bed-e64b-4259-b48f-51beb588599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed dataset\n",
    "df.to_csv(\"preprocessed_passwords.csv\", index=False)\n",
    "print(\"Preprocessed dataset saved as 'preprocessed_passwords.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46668748-0428-499d-95ad-08d2df5d6e21",
   "metadata": {},
   "source": [
    "# II. Data Preprocessing for LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fcb10-4e9c-4723-9e8d-e3fed6c15927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow[and-cuda]\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26500cf3-1f06-4395-82f2-e8d63cd7bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "df = pd.read_csv(\"preprocessed_passwords.csv\", dtype=str, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24afcb-9c31-46e5-b9bf-89acbb48dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values (they cause tokenizer errors)\n",
    "df = df.dropna(subset=[\"Password\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042a862-9d7a-4c6e-be4b-a355549304ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert password strength labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Strength\"] = label_encoder.fit_transform(df[\"Strength\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb7490-883e-4125-aa32-082d22c94b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all passwords are strings\n",
    "df[\"Password\"] = df[\"Password\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e077a21-1622-4296-87a0-834da249d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer with limited vocab size to reduce memory usage\n",
    "tokenizer = Tokenizer(char_level=True, num_words=10000)  # Limit vocab size to optimize memory\n",
    "tokenizer.fit_on_texts(df[\"Password\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f206eee-b37f-4b48-8424-e4c3612925db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert passwords to sequences\n",
    "sequences = tokenizer.texts_to_sequences(df[\"Password\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e885fc3-d151-4000-a505-b0aad5c9e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences dynamically based on 95th percentile length to avoid long padding\n",
    "max_length = int(np.percentile([len(seq) for seq in sequences], 95))  # Avoid extreme long passwords\n",
    "X = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72004c-9f71-4d5d-bd6b-34184132fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numpy array\n",
    "y = np.array(df[\"Strength\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb04ce-b2b4-4b75-9901-073d59cbaae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad658ed-fa56-48c4-bdbe-a7451320ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data\n",
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "print(\"Preprocessed data saved for LSTM training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51675971-e831-4940-a82b-df693c63be64",
   "metadata": {},
   "source": [
    "# III. Building & Training the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b6192-736d-4a7f-bbf6-9a576c97cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=128),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # 3 classes: Weak, Moderate, Strong\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c4441-cc29-45d2-9bcc-2d0618c76327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996a0dd-e974-4c33-a61f-07d16d7b02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"password_strength_lstm.h5\")\n",
    "print(\"LSTM model trained and saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c403cb-50a2-43c1-9dbc-dd584a1e8503",
   "metadata": {},
   "source": [
    "# IV. Password Strength UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dca807-9f47-47b6-9d08-b43c0e511684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
